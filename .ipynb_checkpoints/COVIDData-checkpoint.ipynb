{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misinformation regarding Corona-virus\n",
    "### Corona Drama (Team 8)\n",
    "Muskaan Narula (muskaannarula22),\n",
    " Yesrat Rahman (yr2818), \n",
    " Yohannes Afework (yohannes17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Listing:\n",
    "### Muskaan \n",
    "* Reddit API data collection using subreddit \"Covid19Conspiracy\". Misinforamtion posts related to COVID-19. \n",
    "* Reddit API data collection from trusted newspaper and channels. Valid posts related to COVID-19.\n",
    "[//]: # (Hello)\n",
    "### Yesrat  \n",
    "* Problem Statement, Description of the project topic, Research Process.\n",
    "* Research Questionnaires to be Answered.\n",
    "[//]: #(Hello)\n",
    "### Yohannes   \n",
    "* Detailed description of the data we gathered. \n",
    "* Description of how we processed it. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement: \n",
    "Understanding the spread of information and misinformation on social media regarding Coronavirus using Reddit API data. \n",
    "### Description of the Project Topic: \n",
    "COVID-19 has become the greatest public health challenge for the whole world, and people are dramatically relying on social media to get information such as what should be done to be safe, how many people are infected or dead, or what are the cure. Observing from the beginning of the pandemic, we realized there were so many misleading information posted on social media about the cure, but in reality, there was not any approved cure declared yet. Spreading the misinformation can take people’s lives and cause chaos. Those who are seeking information on social media platforms do not know what to trust or where should look for valid information. It is necessary for all to understand which are the sites and resources we can trust. \n",
    "\n",
    "While it is possible to look at past data on misinformation to understand the spread of it across social media, it won’t be representative of the global pandemic. We need to look at the trends in misinformation related to Coronavirus in order to fully understand how to detect it, and eventually prevent its spread.\n",
    "\n",
    "For our projects, we will be scraping through COVID 19 related data from reddit, where most of the people rely on for information. Be able to observe how quickly this social media can spread misinformation, we can definitely use that to alert general people that we should trust only the health department, or any government approved organization’s provided information. \n",
    "\n",
    "### Research Process:\n",
    "\n",
    "1. Scrape the Reddit API to get the posts related to COVID-19. \n",
    "2. Get fake news from subreddit \"Covid19Conspiracy.\"  \n",
    "3. Get some valid post about Coronavirus from trusted newspaper and channels. \n",
    "4. Check how many times one post is shared and get the graph out of it based on the speed of sharing. \n",
    "5. Check how many times a post is liked or disliked and compare those two. \n",
    "6. Show the ratio of verified information to misinformation on Reddit.\n",
    "7. Do a sentiment analysis on the fake news and compare that analysis with the CDC post sentiment analysis. \n",
    "8. What steps Reddit and some other social media has taken to slower the spread of misinformation (If someone search about Coronavirus on Reddit, it will automatically suggest you to the CDC webpage).\n",
    "9. Most importantly, we will be looking for a specific pattern that fake news sites follow.\n",
    "\n",
    "### Research Questionnaires to be Answered:\n",
    "1. By looking at the spread of misinformation and information graph, we will be able to answer how quickly misinformation and information spread throughout social media. Does it spread faster or slower than valid information? \n",
    "2. From the comparison between liked and disliked numbers, we can answer if people are supporting or trusting the fake news than valid news. Hpw many people are trusting fake sites? \n",
    "3. Sentimental analysis on both fake and valid posts will tell us how much positive or negative vibe they contain. Do they use certain type of wording or sentences?  \n",
    "4. If we can find any specific pattern that fake news sites follow, we can give some general advice to the public to be aware of the fake news. Using our research, they should be able to distinguish between fake and valid news.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import isfile\n",
    "import praw\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "import json\n",
    "\n",
    "# loading credentials function\n",
    "def load_key(filename):\n",
    "    with open(filename) as f:\n",
    "        key_dict = json.load(f)\n",
    "    return key_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accessing search API\n",
    "key = load_key('../Redditkey.json')\n",
    "\n",
    "reddit = praw.Reddit(client_id = key['client_id'],\n",
    "                     client_secret = key['client_secret'],\n",
    "                     user_agent =key['user_agent'],\n",
    "                     username = key['username'], \n",
    "                     password =key['password']  ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ....done\n",
      "5 ....done\n",
      "10 ....done\n",
      "15 ....done\n",
      "20 ....done\n",
      "25 ....done\n",
      "30 ....done\n",
      "35 ....done\n",
      "40 ....done\n",
      "45 ....done\n",
      "50 ....done\n",
      "55 ....done\n",
      "60 ....done\n",
      "65 ....done\n",
      "70 ....done\n",
      "75 ....done\n",
      "80 ....done\n",
      "85 ....done\n",
      "90 ....done\n",
      "95 ....done\n",
      "100 ....done\n",
      "105 ....done\n",
      "110 ....done\n",
      "115 ....done\n",
      "120 ....done\n",
      "125 ....done\n",
      "130 ....done\n",
      "135 ....done\n",
      "140 ....done\n",
      "145 ....done\n",
      "150 ....done\n",
      "155 ....done\n",
      "160 ....done\n",
      "165 ....done\n",
      "170 ....done\n",
      "175 ....done\n",
      "180 ....done\n",
      "185 ....done\n",
      "190 ....done\n",
      "195 ....done\n",
      "Collection Complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(196, 9)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting posts from Covid19Conspiracy subreddit known to have misinformation\n",
    "subreddit = reddit.subreddit('Covid19Conspiracy')\n",
    "\n",
    "from collections import defaultdict\n",
    "posts = defaultdict(list)\n",
    "\n",
    "progress = 0\n",
    "for sub in subreddit.top(limit=500):\n",
    "    if (progress %5 == 0):\n",
    "        print(progress, \"....done\")\n",
    "    posts['Title'].append(sub.title) #post ID\n",
    "    posts[\"Author\"].append(sub.author) #author\n",
    "    posts[\"Created\"].append(str(sub.created).strip('.0')) #created date\n",
    "    posts[\"Comments\"].append(sub.num_comments) #number of comments\n",
    "    posts[\"Score\"].append(sub.score) #score\n",
    "    posts[\"Upvote\"].append(sub. upvote_ratio) #score\n",
    "    posts[\"Edited\"].append(sub.edited) #edited or not\n",
    "    posts[\"Url\"].append(sub.url) #link\n",
    "    posts[\"Body\"].append(sub.selftext) #post text\n",
    "    progress += 1\n",
    "\n",
    "print(\"Collection Complete!\")\n",
    "import pandas\n",
    "misinfo = pandas.DataFrame(posts) #dataframe of data\n",
    "misinfo.shape\n",
    "#stores data into two CSV files (misinfo.csv, other.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muskaan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "#stroing misinfo in covid19conspiracy.csv file\n",
    "misinfo.body = misinfo.Body.map(lambda x: 'empty' if len(x)==0 else x)\n",
    "misinfo.to_csv('./covid19conspiracy.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ....done\n",
      "50 ....done\n",
      "100 ....done\n",
      "150 ....done\n",
      "200 ....done\n",
      "250 ....done\n",
      "300 ....done\n",
      "350 ....done\n",
      "400 ....done\n",
      "450 ....done\n",
      "500 ....done\n",
      "550 ....done\n",
      "600 ....done\n",
      "650 ....done\n",
      "700 ....done\n",
      "750 ....done\n",
      "800 ....done\n",
      "850 ....done\n",
      "Collection Complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(124, 9)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extracting data for factual information\n",
    "subreddit = reddit.subreddit('Coronavirus')\n",
    "\n",
    "from collections import defaultdict\n",
    "posts = defaultdict(list)\n",
    "trusted = ['bbc.co.uk', 'usatoday.com', 'cnn.com', 'cnbc.com', 'washingtonpost.com',\n",
    "           'forbes.com', 'bloomberg.com', 'theguardian.com', 'foxnews.com']\n",
    "def is_trusted(url):\n",
    "    for item in trusted:\n",
    "        if (item in url):\n",
    "            return True\n",
    "    return False\n",
    "progress = 0\n",
    "for sub in subreddit.top(limit=900):\n",
    "    if (progress %50 == 0):\n",
    "        print(progress, \"....done\")\n",
    "    if(is_trusted(sub.url)):\n",
    "        posts['Title'].append(sub.title) #post ID\n",
    "        posts[\"Author\"].append(sub.author) #author\n",
    "        posts[\"Created\"].append(str(sub.created).strip('.0')) #created date\n",
    "        posts[\"Comments\"].append(sub.num_comments) #number of comments\n",
    "        posts[\"Score\"].append(sub.score) #score\n",
    "        posts[\"Upvote\"].append(sub. upvote_ratio) #score\n",
    "        posts[\"Edited\"].append(sub.edited) #edited or not\n",
    "        posts[\"Url\"].append(sub.url) #link\n",
    "        posts[\"Body\"].append(sub.selftext) #post text\n",
    "    progress += 1\n",
    "\n",
    "print(\"Collection Complete!\")\n",
    "import pandas\n",
    "fact = pandas.DataFrame(posts) #dataframe of data\n",
    "fact.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muskaan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#stroing misinfo in covid19facts.csv file\n",
    "fact.body = fact.Body.map(lambda x: 'empty' if len(x)==0 else x)\n",
    "fact.to_csv('./covid19facts.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opens misinformation CSV file\n",
    "import csv\n",
    "orig = pandas.read_csv('covid19facts.csv')\n",
    "facts = orig.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opens factual CSV file\n",
    "orig = pandas.read_csv('covid19conspiracy.csv')\n",
    "fakenews = orig.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124, 9)\n",
      "(196, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Created</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Score</th>\n",
       "      <th>Upvote</th>\n",
       "      <th>Edited</th>\n",
       "      <th>Url</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>They knew?</td>\n",
       "      <td>yungchewie</td>\n",
       "      <td>1585043007</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>0.83</td>\n",
       "      <td>False</td>\n",
       "      <td>https://i.redd.it/fk0jvlhhzio41.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Covid-19: Coverup for Economic Collapse</td>\n",
       "      <td>lukenishihama</td>\n",
       "      <td>1584955881</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1585101372.0</td>\n",
       "      <td>https://www.reddit.com/r/Covid19Conspiracy/com...</td>\n",
       "      <td>We're being lied to about this virus through a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CONVENIENT TIMING OF COVID 19</td>\n",
       "      <td>QuaesitorSapientiae</td>\n",
       "      <td>1584795642</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1584767475.0</td>\n",
       "      <td>https://www.reddit.com/r/Covid19Conspiracy/com...</td>\n",
       "      <td>There has been a lot of convenient timing and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Gov’t test run</td>\n",
       "      <td>violet_wraith33</td>\n",
       "      <td>1584610616</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>0.90</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.reddit.com/r/Covid19Conspiracy/com...</td>\n",
       "      <td>It feels like the government is testing us to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Whole thing does seem a little fishy don’t it</td>\n",
       "      <td>Affflackk</td>\n",
       "      <td>1585137422</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>0.86</td>\n",
       "      <td>False</td>\n",
       "      <td>https://i.redd.it/ge65nnk8sqo41.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Title               Author  \\\n",
       "0                                     They knew?           yungchewie   \n",
       "1        Covid-19: Coverup for Economic Collapse        lukenishihama   \n",
       "2                  CONVENIENT TIMING OF COVID 19  QuaesitorSapientiae   \n",
       "3                                 Gov’t test run      violet_wraith33   \n",
       "4  Whole thing does seem a little fishy don’t it            Affflackk   \n",
       "\n",
       "      Created  Comments  Score  Upvote        Edited  \\\n",
       "0  1585043007        16     24    0.83         False   \n",
       "1  1584955881         7     25    0.89  1585101372.0   \n",
       "2  1584795642         6     24    0.92  1584767475.0   \n",
       "3  1584610616         7     23    0.90         False   \n",
       "4  1585137422         4     18    0.86         False   \n",
       "\n",
       "                                                 Url  \\\n",
       "0                https://i.redd.it/fk0jvlhhzio41.jpg   \n",
       "1  https://www.reddit.com/r/Covid19Conspiracy/com...   \n",
       "2  https://www.reddit.com/r/Covid19Conspiracy/com...   \n",
       "3  https://www.reddit.com/r/Covid19Conspiracy/com...   \n",
       "4                https://i.redd.it/ge65nnk8sqo41.jpg   \n",
       "\n",
       "                                                Body  \n",
       "0                                                NaN  \n",
       "1  We're being lied to about this virus through a...  \n",
       "2  There has been a lot of convenient timing and ...  \n",
       "3  It feels like the government is testing us to ...  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic statistics\n",
    "print(facts.shape)\n",
    "print(fakenews.shape)\n",
    "facts.head()\n",
    "fakenews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
